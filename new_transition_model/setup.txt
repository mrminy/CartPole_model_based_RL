these models are trained with 64 - 64 - 128 - 64 - 64
                             encoder transition decoder
Trained on full data set (2.2 mill)