Baseline
[207, 472, 220, 174, 312, 198, 255, 163, 253, 235, 325, 361, 580, 267, 281, 302, 207, 327, 277, 268, 193, 291, 327, 192, 190, 314, 231, 250, 173, 417, 260, 267, 164, 227, 257, 212, 333, 215, 250, 325, 386, 273, 252, 295, 232, 185, 218, 295, 307, 351]
Avg: 271.32
Std: 78.8460373132

[220, 224, 452, 284, 265] - 0.01

[220, 184, 185, 191, 285] - lr 0.001

[256, 157, 314, 916, 123, 181, 433, 260, 449, 139] - lr 0.001, pre-training 100 games (max 25 steps)
[140, 171, 215, 149, 460, 139, 143, 343, 270, 222] - lr 0.001, pre-training 100 games (max 25 steps), keeping ER
[150, 226, 135, 140, 145, 137, 142, 161, 138, 133] - lr 0.001, pre-training 200 games
Avg: 150.7
Std: 26.2832646374
[331, 207, 158, 277, 387, 999, 421, 166, 185, 163] - lr 0.001, pre-training 100 games (no explore in real life)
[209, 99, 99, 99, 365, 99, 99, 99, 113, 140] - lr 0.01, pre-training 200 games (no explore in real life), keeping ER
Avg: 142.1
Std: 81.3368919986


lr 0.001,
[238, 233, 272, 222, 215, 233, 227, 329, 217, 257]
Avg: 244.3
Std: 32.8604625652
Avg(5): 222
Std(5): 6.0827625303

Model based exploration
[401, 141, 176, 251, 203, 251, 329, 259, 999, 203]
Avg: 321.3
Std: 236.867916781
Avg(5): 194.8
Std(5): 40.4376062595

[224, 154, 164, 168, 131, 117, 167, 135, 122, 145] - imagination rollouts from current state, exploration x1.25
Avg: 152.7
Std: 29.5162667016

[173, 144, 125, 139, 155, 154, 160, 166, 130, 154] - imagination rollouts from current state, only exploration
Avg: 150.0
Std: 14.5739493618

[126, 141, 163, 151, 169, 137, 155, 128, 137, 153] - imagination rollouts from current state, only exploration in im and no exploration in real life
Avg: 146.0
Std: 13.7258879494


[260, 383, 310, 243, 290, 283, 375, 283, 305, 194] - pre-training 200 games with 10000 steps (30 epochs) model
Avg: 292.6
Std: 53.7162917559


H = 200
H2 = 200
batch_number = 500
gamma = 0.99
num_between_q_copies = 150
explore_decay = 0.9995  # Exploration decay per step
min_explore = 0.01
max_steps = 200
reward_goal = 195
memory_size = 100000
learning_rate = 0.001
Pre-training 200 (only exploring), imagination rollouts (only exploring), no exploration in real life
Full data set:
[99, 99, 99, 99, 99, 99, 99, 99, 99, 99]
Avg: 99.0
Std: 0.0

200k data set
[415, 112, 696, 422, 872, 694, 539, 132, 460, 405]
Avg: 474.7
Std: 227.916234613



200k data set (only pre-training 200 full learning):
[345, 317, 255, 176, 211, 174, 240, 202, 290, 172]
Avg: 238.2
Std: 59.1672206547

10k data set (only pre-training 200 full learning):
[246, 315, 303, 322, 190, 199, 262, 307, 243, 315]
Avg: 270.2
Std: 46.9271776266
10k_2
[278, 150, 239, 264, 141, 360, 257, 377, 265, 266]
Avg: 259.7
Std: 71.2741888765




